{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb86d449",
   "metadata": {},
   "source": [
    "Intructional Finetuning: Prepare dataset -> Finetunee -> Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1646f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from Pretraining import GPTModel\n",
    "from GPT2 import load_weights_into_gpt\n",
    "from GPT_architecture import Generate_text\n",
    "from Pretraining import text_to_token_ids, token_ids_to_txt, generate\n",
    "from Pretraining import (\n",
    "        calc_loss_loader,\n",
    "        train_model_simple,\n",
    "        plot_losses,\n",
    "        generate_and_print_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01be32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current dataset has instruction, i/p, respone. I am using Alpaca prompt, hihi\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "            f\"Below is an instruction that describes a task. \"\n",
    "            f\"Write a response that appropriately completes the request.\"\n",
    "            f\"\\n\\n## Instruction:\\n{entry['instruction']}\"\n",
    "            )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466c7be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evaluate the following phrase by transforming ...</td>\n",
       "      <td>freind --&gt; friend</td>\n",
       "      <td>The spelling of the given phrase \"freind\" is i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edit the following sentence for grammar.</td>\n",
       "      <td>He go to the park every day.</td>\n",
       "      <td>He goes to the park every day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convert 45 kilometers to meters.</td>\n",
       "      <td></td>\n",
       "      <td>45 kilometers is 45000 meters.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rewrite this sentence to start with 'Although'...</td>\n",
       "      <td></td>\n",
       "      <td>Although it was raining, they went for a walk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the first 10 square numbers?</td>\n",
       "      <td></td>\n",
       "      <td>1, 4, 9, 16, 25, 36, 49, 64, 81, 100.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Evaluate the following phrase by transforming ...   \n",
       "1           Edit the following sentence for grammar.   \n",
       "2                   Convert 45 kilometers to meters.   \n",
       "3  Rewrite this sentence to start with 'Although'...   \n",
       "4              What are the first 10 square numbers?   \n",
       "\n",
       "                          input  \\\n",
       "0             freind --> friend   \n",
       "1  He go to the park every day.   \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "\n",
       "                                              output  \n",
       "0  The spelling of the given phrase \"freind\" is i...  \n",
       "1                     He goes to the park every day.  \n",
       "2                     45 kilometers is 45000 meters.  \n",
       "3     Although it was raining, they went for a walk.  \n",
       "4              1, 4, 9, 16, 25, 36, 49, 64, 81, 100.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_json(\"instruction-data.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8ec62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "## Instruction:\n",
      "Edit the following sentence for grammar.\n",
      "\n",
      "### Input:\n",
      "He go to the park every day.\n",
      "\n",
      "### Respone:\n",
      "He goes to the park every day.\n"
     ]
    }
   ],
   "source": [
    "model_ip= format_input(data.iloc[1])\n",
    "desired_output= f\"\\n\\n### Respone:\\n{data.iloc[1]['output']}\"\n",
    "print(model_ip+ desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabe28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instruction_dataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for _, entry in data.iterrows(): \n",
    "            entry = entry.to_dict()\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                    tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d409ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom collate function coz why not? hehe, well it is needed to pad training egs to same len\n",
    "# but diff batches can have diff lens, this minimizes unnecessary padding.\n",
    "def custom_collate_draft(\n",
    "        batch,\n",
    "        pad_token_id= 50256,\n",
    "        device= \"cpu\"\n",
    "):\n",
    "    batch_max_length= max(len(item)+1 for item in batch)\n",
    "    input_lst= []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item=item.copy()\n",
    "        new_item+=[pad_token_id]\n",
    "\n",
    "        padded=(\n",
    "            new_item+[pad_token_id]* (batch_max_length-len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs= torch.tensor(padded[:-1])\n",
    "        input_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor= torch.stack(input_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2121aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   12,   131,    12,     1,   122],\n",
      "        [   90,    98,    90,     1, 50256],\n",
      "        [    0, 50256, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "ip1= [12,131,12,1,122]\n",
    "ip2= [90,98,90,1]\n",
    "ip3=[0]\n",
    "batch=(ip1, ip2, ip3)\n",
    "print(custom_collate_draft(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671cf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this custom_collate () is to return target token ids with addition to input token ids\n",
    "def custom_collate(\n",
    "        batch,\n",
    "        pad_token_id= 50256,\n",
    "        device= \"cpu\"\n",
    "):\n",
    "    batch_max_length= max(len(item)+1 for item in batch)\n",
    "    input_lst, target_lsts= [],[]\n",
    "\n",
    "    for item in batch:\n",
    "        new_item=item.copy()\n",
    "        new_item+=[pad_token_id]\n",
    "\n",
    "        padded=(\n",
    "            new_item+[pad_token_id]* (batch_max_length-len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs= torch.tensor(padded[:-1])\n",
    "        targets= torch.tensor(padded[:-1])\n",
    "\n",
    "        input_lst.append(inputs)\n",
    "        target_lsts.append(targets)\n",
    "    \n",
    "    inputs_tensor= torch.stack(input_lst).to(device)\n",
    "    target_tensor= torch.stack(target_lsts).to(device)\n",
    "\n",
    "    return inputs_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1545ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   12,   131,    12,     1,   122],\n",
      "        [   90,    98,    90,     1, 50256],\n",
      "        [    0, 50256, 50256, 50256, 50256]])\n",
      "tensor([[   12,   131,    12,     1,   122],\n",
      "        [   90,    98,    90,     1, 50256],\n",
      "        [    0, 50256, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "ip1= [12,131,12,1,122]\n",
    "ip2= [90,98,90,1]\n",
    "ip3=[0]\n",
    "batch=(ip1, ip2, ip3)\n",
    "ips, tar= custom_collate(batch)\n",
    "print(ips)\n",
    "print(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4e0c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this custom_collate_fn () is to assign -100 to all padding tokens\n",
    "# why? to make sure they don't contribute to train loss calc\n",
    "# to ensure only meaningful data influence our cutie model \n",
    "# why -100? coz cross_entropy function in pytorch ignores target labeled with -100\n",
    "def custom_collate_fn(\n",
    "        batch,\n",
    "        pad_token_id= 50256,\n",
    "        ignore_idx=-100,\n",
    "        allowed_max_len=None,\n",
    "        device= \"cpu\"\n",
    "):\n",
    "    batch_max_length= max(len(item)+1 for item in batch)\n",
    "    input_lst, target_lsts= [],[]\n",
    "\n",
    "    for item in batch:\n",
    "        new_item=item.copy()\n",
    "        new_item+=[pad_token_id]\n",
    "\n",
    "        padded=(\n",
    "            new_item+[pad_token_id]* (batch_max_length-len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs= torch.tensor(padded[:-1])\n",
    "        targets= torch.tensor(padded[:-1])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices= torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]]=ignore_idx\n",
    "        if allowed_max_len is not None:\n",
    "            inputs= inputs[:allowed_max_len]\n",
    "            targets= targets[:allowed_max_len]\n",
    "\n",
    "        input_lst.append(inputs)\n",
    "        target_lsts.append(targets)\n",
    "    \n",
    "    inputs_tensor= torch.stack(input_lst).to(device)\n",
    "    target_tensor= torch.stack(target_lsts).to(device)\n",
    "\n",
    "    return inputs_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00d2930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   12,   131,    12,     1,   122],\n",
      "        [   90,    98,    90,     1, 50256],\n",
      "        [    0, 50256, 50256, 50256, 50256]])\n",
      "tensor([[   12,   131,    12,     1,   122],\n",
      "        [   90,    98,    90,     1, 50256],\n",
      "        [    0, 50256,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "ip1= [12,131,12,1,122]\n",
    "ip2= [90,98,90,1]\n",
    "ip3=[0]\n",
    "batch=(ip1, ip2, ip3)\n",
    "ips, tar= custom_collate_fn(batch)\n",
    "print(ips)\n",
    "print(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956f6407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set len: 935\n",
      "Validation set len: 55\n",
      "Test set len: 110\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train, val and test \n",
    "train_portion = int(len(data) * 0.85) # 85% for train\n",
    "test_portion = int(len(data) * 0.1) # 10% for test\n",
    "val_portion = len(data) - train_portion - test_portion # 5% for val\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set len:\", len(train_data))\n",
    "print(\"Validation set len:\", len(val_data))\n",
    "print(\"Test set len:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83cc9ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c5a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "instruction    Edit the following sentence for grammar.\n",
      "input                      He go to the park every day.\n",
      "output                   He goes to the park every day.\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data.iloc[1]))\n",
    "print(train_data.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13a65b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = Instruction_dataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = Instruction_dataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = Instruction_dataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# Dimensions of the input and target batches generated by the training loader\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2416097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 17.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 647kiB/s] \n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 24.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [04:35<00:00, 5.14MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 2.60MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 583kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 417kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "        \"vocab_size\": 50257,      # Vocabulary size\n",
    "        \"context_length\": 1024,   # Context length\n",
    "        \"drop_rate\": 0.0,         # Dropout rate\n",
    "        \"qkv_bias\": True          # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "        \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "        \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "        \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "        \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55ce35ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e68e3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "## Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "\n",
      "--OUTPUT--\n",
      "\n",
      "\n",
      "'\n",
      "\n",
      "## Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "## Conclusion:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "## Example\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data.iloc[0])\n",
    "print(input_text)\n",
    "token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),\n",
    "        max_new_tokens=35,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_txt(token_ids, tokenizer)\n",
    "\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(\"\\n\\n--OUTPUT--\\n\\n\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83e7953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # we don't have any gpu but still i'll write it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c14ccdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.514548873901367\n",
      "Validation loss: 7.621609210968018\n",
      "Beginning training\n",
      "Ep1(Step 000000):Train loss4.442Val loss4.588\n",
      "Ep1(Step 000005):Train loss0.680Val loss0.709\n",
      "Ep1(Step 000010):Train loss0.138Val loss0.134\n",
      "Ep1(Step 000015):Train loss0.053Val loss0.040\n",
      "Ep1(Step 000020):Train loss0.021Val loss0.022\n",
      "Ep1(Step 000025):Train loss0.007Val loss0.015\n",
      "Ep1(Step 000030):Train loss0.007Val loss0.012\n",
      "Ep1(Step 000035):Train loss0.005Val loss0.009\n",
      "Ep1(Step 000040):Train loss0.002Val loss0.009\n",
      "Ep1(Step 000045):Train loss0.001Val loss0.005\n",
      "Ep1(Step 000050):Train loss0.005Val loss0.003\n",
      "Ep1(Step 000055):Train loss0.003Val loss0.003\n",
      "Ep1(Step 000060):Train loss0.002Val loss0.002\n",
      "Ep1(Step 000065):Train loss0.003Val loss0.002\n",
      "Ep1(Step 000070):Train loss0.001Val loss0.003\n",
      "Ep1(Step 000075):Train loss0.003Val loss0.003\n",
      "Ep1(Step 000080):Train loss0.001Val loss0.003\n",
      "Ep1(Step 000085):Train loss0.002Val loss0.003\n",
      "Ep1(Step 000090):Train loss0.004Val loss0.003\n",
      "Ep1(Step 000095):Train loss0.002Val loss0.003\n",
      "Ep1(Step 000100):Train loss0.001Val loss0.002\n",
      "Ep1(Step 000105):Train loss0.004Val loss0.001\n",
      "Ep1(Step 000110):Train loss0.002Val loss0.001\n",
      "Ep1(Step 000115):Train loss0.002Val loss0.001\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'\n",
      "Ep2(Step 000120):Train loss0.003Val loss0.001\n",
      "Ep2(Step 000125):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000130):Train loss0.000Val loss0.001\n",
      "Ep2(Step 000135):Train loss0.000Val loss0.001\n",
      "Ep2(Step 000140):Train loss0.009Val loss0.001\n",
      "Ep2(Step 000145):Train loss0.000Val loss0.001\n",
      "Ep2(Step 000150):Train loss0.001Val loss0.000\n",
      "Ep2(Step 000155):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000160):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000165):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000170):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000175):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000180):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000185):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000190):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000195):Train loss0.012Val loss0.000\n",
      "Ep2(Step 000200):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000205):Train loss0.000Val loss0.000\n",
      "Ep2(Step 000210):Train loss0.000Val loss0.001\n",
      "Ep2(Step 000215):Train loss0.000Val loss0.001\n",
      "Ep2(Step 000220):Train loss0.006Val loss0.002\n",
      "Ep2(Step 000225):Train loss0.002Val loss0.001\n",
      "Ep2(Step 000230):Train loss0.000Val loss0.001\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'\n",
      "Training completed in 61.49 minutes.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAATjZJREFUeJzt3Xd8FNX6+PHPbM1uOoE0IKFFei+5IagokSIXAQvI5WpQlCuCyEUR+aEU/SqoiFi42MGCoKggKlKlKNKkI4iANCEhIqSSunt+fyxZWRIgCSGzJM/79dpXMjNnzjxnZnefPVM1pZRCCCGEEF7JoHcAQgghhLg4SdRCCCGEF5NELYQQQngxSdRCCCGEF5NELYQQQngxSdRCCCGEF5NELYQQQngxSdRCCCGEF5NELYQQQngxSdRCXGMOHz6Mpmls375d71CEEBVAErUQOtA07ZKviRMn6h2iEMJLmPQOQIiqKCkpyf3/p59+yvjx49m3b597nJ+fnx5hCSG8kPSohdBBeHi4+xUYGIimae7h0NBQpk2bRq1atbBarbRq1YolS5ZctC6Hw8H9999Po0aNOHr0KABfffUVbdq0wcfHh3r16jFp0iQKCgrc82iaxrvvvkvfvn2x2+3ExMSwaNEi9/QzZ84wcOBAatSogc1mIyYmhlmzZl00hs8//5zmzZtjs9kICQkhISGBrKws9/R3332Xxo0b4+PjQ6NGjfjf//7nMf+xY8fo168fQUFBVKtWjd69e3P48GH39EGDBtGnTx+mTp1KREQEISEhDBs2jPz8/BKvcyGuWUoIoatZs2apwMBA9/C0adNUQECAmjt3rvr111/VE088ocxms/rtt9+UUkodOnRIAWrbtm0qJydH9e3bV7Vu3VqlpKQopZRau3atCggIULNnz1YHDx5Uy5YtU3Xq1FETJ050LwNQtWrVUp988onav3+/GjFihPLz81N//fWXUkqpYcOGqVatWqnNmzerQ4cOqeXLl6tFixYVG/+JEyeUyWRS06ZNU4cOHVI7d+5UM2bMUBkZGUoppT7++GMVERGhvvjiC/X777+rL774QlWrVk3Nnj1bKaVUXl6eaty4sbr//vvVzp071Z49e9S//vUv1bBhQ5Wbm6uUUioxMVEFBASohx56SO3du1d9/fXXym63q7fffrt8N4YQXkgStRA6uzBRR0ZGqueee86jTPv27dXDDz+slPo7Uf/www+qS5cuqlOnTio1NdVdtkuXLur555/3mP+jjz5SERER7mFAPfXUU+7hzMxMBajvvvtOKaVUr1691H333Vei+Lds2aIAdfjw4WKn169fX33yySce45599lkVFxfnjq1hw4bK6XS6p+fm5iqbzaaWLl2qlHIl6ujoaFVQUOAuc9ddd6n+/fuXKEYhrmVyjFoIL5Kens6JEyeIj4/3GB8fH8+OHTs8xg0YMIBatWrx/fffY7PZ3ON37NjBunXreO6559zjHA4HOTk5nD17FrvdDkCLFi3c0319fQkICCAlJQWAoUOHcscdd7B161a6du1Knz596NixY7Ext2zZki5dutC8eXO6detG165dufPOOwkODiYrK4uDBw8yePBgHnzwQfc8BQUFBAYGuuM9cOAA/v7+HvXm5ORw8OBB93DTpk0xGo3u4YiICHbt2nWJtSlE5SCJWohr1K233srHH3/M+vXrufnmm93jMzMzmTRpErfffnuReXx8fNz/m81mj2mapuF0OgHo0aMHR44cYfHixSxfvpwuXbowbNgwpk6dWqROo9HI8uXL+emnn1i2bBmvv/4648aNY+PGje4fBe+88w6xsbFF5iuMt23btsyZM6dI3TVq1ChRvEJUZpKohfAiAQEBREZGsm7dOm688Ub3+HXr1tGhQwePskOHDqVZs2bcdtttfPvtt+7ybdq0Yd++fTRo0OCKYqlRowaJiYkkJiZy/fXXM3r06GITNbiSZnx8PPHx8YwfP57o6GgWLFjAqFGjiIyM5Pfff2fgwIHFztumTRs+/fRTQkNDCQgIuKKYhaiMJFEL4WVGjx7NhAkTqF+/Pq1atWLWrFls37692B7nI488gsPh4J///CffffcdnTp1Yvz48fzzn/8kKiqKO++8E4PBwI4dO9i9ezf/93//V6IYxo8fT9u2bWnatCm5ubl88803NG7cuNiyGzduZOXKlXTt2pXQ0FA2btzIn3/+6S4/adIkRowYQWBgIN27dyc3N5eff/6ZM2fOMGrUKAYOHMhLL71E7969eeaZZ6hVqxZHjhzhyy+/5IknnqBWrVplX5lCVAKSqIXwMiNGjCAtLY3HHnuMlJQUmjRpwqJFi4iJiSm2/MiRI3E6ndx6660sWbKEbt268c033/DMM8/wwgsvYDabadSoEQ888ECJY7BYLIwdO5bDhw9js9m4/vrrmTdvXrFlAwICWLt2LdOnTyc9PZ3o6GhefvllevToAcADDzyA3W7npZdeYvTo0fj6+tK8eXNGjhwJgN1uZ+3atYwZM4bbb7+djIwMatasSZcuXaSHLQSgKaWU3kEIIYQQonhywxMhhBDCi0miFkIIIbyYJGohhBDCi0miFkIIIbyYJGohhBDCi0miFkIIIbyYJGpgxowZ1KlTBx8fH2JjY9m0aZPeIRVr8uTJtG/fHn9/f0JDQ+nTp4/HM4zBdX/kYcOGERISgp+fH3fccQcnT570KHP06FF69uyJ3W4nNDSU0aNHezwCEWD16tW0adMGq9VKgwYNmD17dpF49FhvU6ZMQdM09zW4UDnbfPz4cf79738TEhKCzWajefPm/Pzzz+7pSinGjx9PREQENpuNhIQE9u/f71HH6dOnGThwIAEBAQQFBTF48GAyMzM9yuzcuZPrr78eHx8fateuzYsvvlgklvnz59OoUSN8fHxo3rw5ixcvLvf2OhwOnn76aerWrYvNZqN+/fo8++yznH/1aGVo89q1a+nVqxeRkZFomsbChQs9pntTG0sSy5W2OT8/nzFjxtC8eXN8fX2JjIzk3nvv5cSJE9d0m8udfs8D8Q7z5s1TFotFvf/+++qXX35RDz74oAoKClInT57UO7QiunXrpmbNmqV2796ttm/frm699VYVFRWlMjMz3WUeeughVbt2bbVy5Ur1888/q3/84x+qY8eO7ukFBQWqWbNmKiEhQW3btk0tXrxYVa9eXY0dO9Zd5vfff1d2u12NGjVK7dmzR73++uvKaDSqJUuWuMvosd42bdqk6tSpo1q0aKEeffTRStvm06dPq+joaDVo0CC1ceNG9fvvv6ulS5eqAwcOuMtMmTJFBQYGqoULF6odO3ao2267TdWtW1dlZ2e7y3Tv3l21bNlSbdiwQf3www+qQYMGasCAAe7paWlpKiwsTA0cOFDt3r1bzZ07V9lsNvXWW2+5y6xbt04ZjUb14osvqj179qinnnpKmc1mtWvXrnJt83PPPadCQkLUN998ow4dOqTmz5+v/Pz81Kuvvlqp2rx48WI1btw49eWXXypALViwwGO6N7WxJLFcaZtTU1NVQkKC+vTTT9Wvv/6q1q9frzp06KDatm3rUce11ubyVuUTdYcOHdSwYcPcww6HQ0VGRqrJkyfrGFXJpKSkKECtWbNGKeV605vNZjV//nx3mb179ypArV+/Xinl+tAYDAaVnJzsLjNz5kwVEBDgfvbvE088oZo2beqxrP79+6tu3bq5hyt6vWVkZKiYmBi1fPlydeONN7oTdWVs85gxY1SnTp0uOt3pdKrw8HD10ksvucelpqYqq9Wq5s6dq5RSas+ePQpQmzdvdpf57rvvlKZp6vjx40oppf73v/+p4OBg9zooXHbDhg3dw/369VM9e/b0WH5sbKz6z3/+c2WNvEDPnj3V/fff7zHu9ttvVwMHDlRKVc42X5i0vKmNJYmlPNpcnE2bNilAHTlyRCl17be5PFTpXd95eXls2bKFhIQE9ziDwUBCQgLr16/XMbKSSUtLA6BatWoAbNmyhfz8fI/2NGrUiKioKHd71q9fT/PmzQkLC3OX6datG+np6fzyyy/uMufXUVimsA491tuwYcPo2bNnkbgqY5sXLVpEu3btuOuuuwgNDaV169a888477umHDh0iOTnZI5bAwEBiY2M92hwUFES7du3cZRISEjAYDGzcuNFd5oYbbsBisXi0ed++fZw5c8Zd5lLrpbx07NiRlStX8ttvvwGuR1/++OOP7tuQVsY2X8ib2liSWK6WtLQ0NE0jKCjIHWtlb/PlVOlEferUKRwOh8cXOEBYWBjJyck6RVUyTqeTkSNHEh8fT7NmzQBITk7GYrG43+CFzm9PcnJyse0tnHapMunp6WRnZ1f4eps3bx5bt25l8uTJRaZVxjb//vvvzJw5k5iYGJYuXcrQoUMZMWIEH3zwgUfMl4olOTmZ0NBQj+kmk4lq1aqVy3op7zY/+eST3H333TRq1Aiz2Uzr1q0ZOXKk+4lblbHNF/KmNpYklqshJyeHMWPGMGDAAPd93it7m0tCHspxjRo2bBi7d+/mxx9/1DuUq+rYsWM8+uijLF++3ONZypWZ0+mkXbt2PP/88wC0bt2a3bt38+abb5KYmKhzdFfHZ599xpw5c/jkk09o2rQp27dvZ+TIkURGRlbaNgtP+fn59OvXD6UUM2fO1Dscr1Kle9TVq1fHaDQWOUP45MmThIeH6xTV5Q0fPpxvvvmGVatWeTwCMDw8nLy8PFJTUz3Kn9+e8PDwYttbOO1SZQICArDZbBW63rZs2UJKSgpt2rTBZDJhMplYs2YNr732GiaTibCwsErX5oiICJo0aeIxrnHjxhw9etQj5kvFEh4eTkpKisf0goICTp8+XS7rpbzbPHr0aHevunnz5txzzz3897//de9FqYxtvpA3tbEksZSnwiR95MgRli9f7vHUtMra5tKo0onaYrHQtm1bVq5c6R7ndDpZuXIlcXFxOkZWPKUUw4cPZ8GCBXz//ffUrVvXY3rbtm0xm80e7dm3bx9Hjx51tycuLo5du3Z5vPELPxiFySEuLs6jjsIyhXVU5Hrr0qULu3btYvv27e5Xu3btGDhwoPv/ytbm+Pj4Ipfd/fbbb0RHRwNQt25dwsPDPWJJT09n48aNHm1OTU1ly5Yt7jLff/89TqeT2NhYd5m1a9eSn5/v0eaGDRsSHBzsLnOp9VJezp49i8Hg+XVkNBpxOp1A5WzzhbypjSWJpbwUJun9+/ezYsUKQkJCPKZXxjaXmq6nsnmBefPmKavVqmbPnq327NmjhgwZooKCgjzOEPYWQ4cOVYGBgWr16tUqKSnJ/Tp79qy7zEMPPaSioqLU999/r37++WcVFxen4uLi3NMLL1Xq2rWr2r59u1qyZImqUaNGsZcqjR49Wu3du1fNmDGj2EuV9Fpv55/1XRnbvGnTJmUymdRzzz2n9u/fr+bMmaPsdrv6+OOP3WWmTJmigoKC1FdffaV27typevfuXexlPK1bt1YbN25UP/74o4qJifG4pCU1NVWFhYWpe+65R+3evVvNmzdP2e32Ipe0mEwmNXXqVLV37141YcKEq3J5VmJioqpZs6b78qwvv/xSVa9eXT3xxBOVqs0ZGRlq27Ztatu2bQpQ06ZNU9u2bXOf4exNbSxJLFfa5ry8PHXbbbepWrVqqe3bt3t8r51/Bve11ubyVuUTtVJKvf766yoqKkpZLBbVoUMHtWHDBr1DKhZQ7GvWrFnuMtnZ2erhhx9WwcHBym63q759+6qkpCSPeg4fPqx69OihbDabql69unrsscdUfn6+R5lVq1apVq1aKYvFourVq+exjEJ6rbcLE3VlbPPXX3+tmjVrpqxWq2rUqJF6++23PaY7nU719NNPq7CwMGW1WlWXLl3Uvn37PMr89ddfasCAAcrPz08FBASo++67T2VkZHiU2bFjh+rUqZOyWq2qZs2aasqUKUVi+eyzz9R1112nLBaLatq0qfr222/Lvb3p6enq0UcfVVFRUcrHx0fVq1dPjRs3zuPLujK0edWqVcV+hhMTE72ujSWJ5UrbfOjQoYt+r61ateqabXN505Q679Y/QgghhPAqVfoYtRBCCOHtJFELIYQQXkwStRBCCOHFJFELIYQQXkwStRBCCOHFJFELIYQQXkwSNZCbm8vEiRPJzc3VO5QKUxXbDFWz3dLmqqEqthmqRrvlOmpct4kLDAwkLS3N4x6zlVlVbDNUzXZLm6XNlVlVaLf0qIUQQggvJolaCCGE8GLX9POoCwoK2LZtG2FhYUWevFMaGRkZABw/fpz09PTyCs+rVcU2Q9Vst7RZ2lyZXavtdjqdnDx5ktatW2MyXToVX9PHqDdv3kyHDh30DkMIIYQok02bNtG+fftLlrmme9RhYWGAq6ERERE6RyOEEEKUTFJSEh06dHDnsUu5phN14e7uiIgIatWqpXM0QgghROmU5LCtnEwmhBBCeDFJ1EIIIYQXk0QthBBCeLFr+hi1EEKUN4fDQX5+vt5hiGuc2WzGaDSWS12SqIUQAlBKkZycTGpqqt6hiEoiKCiI8PBwNE27onokURfKzYDk3YCC6I56RyOEqGCFSTo0NBS73X7FX66i6lJKcfbsWVJSUgCu+PJhSdSFUn6FWd0hKBpG7tQ7GiFEBXI4HO4kHRISonc4ohKw2WwApKSkEBoaekW7weVkskI+5566knvt3IJOCFE+Co9J2+12nSMRlUnh++lKz3mQRF3Iei5R56TDtXtXVSHEFZDd3aI8ldf7SRJ1ocIetXJAXpa+sQghhBDnSKI+Z/3RbAo4dwxBdn8LIaqwOnXqMH369BKXX716NZqmXfUz5mfPnk1QUNBVXYY3kkR9jsGgka5cB//JkUQthPB+mqZd8jVx4sQy1bt582aGDBlS4vIdO3YkKSmJwMDAMi1PXJqc9X1OgM1MhrJTTcuEnDS9wxFCiMtKSkpy///pp58yfvx49u3b5x7n5+fn/l8phcPhuOyzjwFq1KhRqjgsFgvh4eGlmkeUnPSozwmwmcng3BmfsutbCHENCA8Pd78CAwPRNM09/Ouvv+Lv7893331H27ZtsVqt/Pjjjxw8eJDevXsTFhaGn58f7du3Z8WKFR71XrjrW9M03n33Xfr27YvdbicmJoZFixa5p1+467twF/XSpUtp3Lgxfn5+dO/e3eOHRUFBASNGjCAoKIiQkBDGjBlDYmIiffr0KdU6mDlzJvXr18disdCwYUM++ugj9zSlFBMnTiQqKgqr1UpkZCQjRoxwT//f//5HTEwMPj4+hIWFceedd5Zq2RVFEvU5AT4m0pUrUedlndE5GiGE3pRSnM0r0OWlyvHKkyeffJIpU6awd+9eWrRoQWZmJrfeeisrV65k27ZtdO/enV69enH06NFL1jNp0iT69evHzp07ufXWWxk4cCCnT5++aPmzZ88ydepUPvroI9auXcvRo0d5/PHH3dNfeOEF5syZw6xZs1i3bh3p6eksXLiwVG1bsGABjz76KI899hi7d+/mP//5D/fddx+rVq0C4IsvvuCVV17hrbfeYv/+/SxcuJDmzZsD8PPPPzNixAieeeYZ9u3bx5IlS7jhhhtKtfyKIru+z/G1mNw96tzMVCw6xyOE0Fd2voMm45fqsuw9z3TDbimfr+dnnnmGW265xT1crVo1WrZs6R5+9tlnWbBgAYsWLWL48OEXrWfQoEEMGDAAgOeff57XXnuNTZs20b1792LL5+fn8+abb1K/fn0Ahg8fzjPPPOOe/vrrrzN27Fj69u0LwBtvvMHixYtL1bapU6cyaNAgHn74YQBGjRrFhg0bmDp1KjfddBNHjx4lPDychIQEzGYzUVFRdOjQAYCjR4/i6+vLP//5T/z9/YmOjqZ169alWn5FkR71OQaDRo7RF5AetRCi8mjXrp3HcGZmJo8//jiNGzcmKCgIPz8/9u7de9kedYsWLdz/+/r6EhAQ4L5FZnHsdrs7SYPrNpqF5dPS0jh58qQ7aQIYjUbatm1bqrbt3buX+Ph4j3Hx8fHs3bsXgLvuuovs7Gzq1avHgw8+yIIFCygoKADglltuITo6mnr16nHPPfcwZ84czp49W6rlVxTpUZ8nz+gHDsjPStU7FCGEzmxmI3ue6abbssuLr6+vx/Djjz/O8uXLmTp1Kg0aNMBms3HnnXeSl5d3yXrMZrPHsKZpOJ3OUpUvz136JVG7dm327dvHihUrWL58OQ8//DAvvfQSa9aswd/fn61bt7J69WqWLVvG+PHjmThxIps3b/a6S8CkR32ePLPrpieObDnrW4iqTtM07BaTLq+reYe0devWMWjQIPr27Uvz5s0JDw/n8OHDV215xQkMDCQsLIzNmze7xzkcDrZu3Vqqeho3bsy6des8xq1bt44mTZq4h202G7169eK1115j9erVrF+/nl27dgFgMplISEjgxRdfZOfOnRw+fJjvv//+Clp2dUiP+jzLA+/khdSbeL5ZR2rqHYwQQlwFMTExfPnll/Tq1QtN03j66acv2TO+Wh555BEmT55MgwYNaNSoEa+//jpnzpwp1Y+U0aNH069fP1q3bk1CQgJff/01X375pfss9tmzZ+NwOIiNjcVut/Pxxx9js9mIjo7mm2++4ffff+eGG24gODiYxYsX43Q6adiw4dVqcplJoj6P2TeIdHJJz5F7fQshKqdp06Zx//3307FjR6pXr86YMWNIT6/4S1LHjBlDcnIy9957L0ajkSFDhtCtW7dSPWWqT58+vPrqq0ydOpVHH32UunXrMmvWLDp37gy4ngc9ZcoURo0ahcPhoHnz5nz99deEhIQQFBTEl19+ycSJE8nJySEmJoa5c+fStGnTq9TistNURR80KEd//PEHtWvX5tixY9SqVeuK63vssx18sfUPnuzRiIdurH/5GYQQlUJOTg6HDh2ibt26+Pj46B1OleR0OmncuDH9+vXj2Wef1TuccnGp91Vp8pf0qM8TTTLPm96lwa8RcOP/9A5HCCEqrSNHjrBs2TJuvPFGcnNzeeONNzh06BD/+te/9A7N63jNyWRTpkxB0zRGjhypWwwhprP8y/Q9151acfnCQgghysxgMDB79mzat29PfHw8u3btYsWKFTRu3Fjv0LyOV/SoN2/ezFtvveVxnZ4eVGBtpuXfSc2wKPrrGokQQlRutWvXLnLGtiie7j3qzMxMBg4cyDvvvENwcLCusVgCwnjNcTtLfHroGocQQghRSPdEPWzYMHr27ElCQsJly+bm5pKenu5+ZWRklGssATbXDoaMnIJyrVcIIYQoK113fc+bN4+tW7d6XPR+KZMnT2bSpElXLZ4AHzP1tePUyjwKea3AYr9qyxJCCCFKQrce9bFjx3j00UeZM2dOiS+HGDt2LGlpae7Xnj17yjWmAJuZeZZnmZ71JJw+WK51CyGEEGWhW496y5YtpKSk0KZNG/c4h8PB2rVreeONN8jNzS1y4bvVasVqtbqHy/sifX8fExnKTg0tHXLkmdRCCCH0p1ui7tKli/t+q4Xuu+8+GjVqxJgxY0p1d5ryEuBj5ui5R106slOp+AiEEEIIT7rt+vb396dZs2YeL19fX0JCQmjWrJk+MfmYSFeuRJ2TkapLDEIIUdE6d+7scQ+LOnXqMH369EvOo2kaCxcuvOJll1c9lzJx4kRatWp1VZdxNel+1rc3MRkNnDW4HgmXI8+kFkJ4uV69etG9e/dip/3www9omsbOnTtLXe/mzZsZMmTIlYbn4WLJMikpiR495JLYS/GKG54UWr16td4hkGv0AycUZMmjLoUQ3m3w4MHccccd/PHHH0XuFz1r1izatWtXphtJ1ahRo7xCvKzw8PAKW9a1SnrUF8g3+QFQcFZ61EII7/bPf/6TGjVqMHv2bI/xmZmZzJ8/n8GDB/PXX38xYMAAatasid1up3nz5sydO/eS9V6463v//v3ccMMN+Pj40KRJE5YvX15knjFjxnDddddht9upV68eTz/9NPn5+YDrcZOTJk1ix44daJqGpmnumC/c9b1r1y5uvvlmbDYbISEhDBkyhMzMTPf0QYMG0adPH6ZOnUpERAQhISEMGzbMvayScDqdPPPMM9SqVQur1UqrVq1YsmSJe3peXh7Dhw8nIiICHx8foqOjmTx5MgBKKSZOnEhUVBRWq5XIyEhGjBhR4mWXhVf1qL1Bvtkf8sCZLT1qIQSQl1X6eYxWMJ77enUUgCMXNAOYbZev1+Jb4sWYTCbuvfdeZs+ezbhx49zPcp4/fz4Oh4MBAwaQmZlJ27ZtGTNmDAEBAXz77bfcc8891K9fnw4dOlx2GU6nk9tvv52wsDA2btxIWlpasc9k8Pf3Z/bs2URGRrJr1y4efPBB/P39eeKJJ+jfvz+7d+9myZIl7mdFBwYGFqkjKyuLbt26ERcXx+bNm0lJSeGBBx5g+PDhHj9GVq1aRUREBKtWreLAgQP079+fVq1a8eCDD5Zovb366qu8/PLLvPXWW7Ru3Zr333+f2267jV9++YWYmBhee+01Fi1axGeffUZUVBTHjh3j2LFjAHzxxRe88sorzJs3j6ZNm5KcnMyOHTtKtNyykkR9AafFH7JAyeVZQgiA5yNLP89ds6FpX9f/v34N8wdBdCe479u/y0xvDmf/KjrvxNJ1Eu6//35eeukl1qxZ434O86xZs7jjjjsIDAwkMDCQxx9/3F3+kUceYenSpXz22WclStQrVqzg119/ZenSpURGutbF888/X+S48lNPPeX+v06dOjz++OPMmzePJ554ApvNhp+fHyaT6ZK7uj/55BNycnL48MMP8fV1/WB544036NWrFy+88AJhYWEABAcH88Ybb2A0GmnUqBE9e/Zk5cqVJU7UU6dOZcyYMdx9990AvPDCC6xatYrp06czY8YMjh49SkxMDJ06dULTNKKjo93zHj16lPDwcBISEjCbzURFRZVoPV4J2fV9AWUNAEDLk0QthPB+jRo1omPHjrz//vsAHDhwgB9++IHBgwcDrvtTPPvsszRv3pxq1arh5+fH0qVLOXr0aInq37t3L7Vr13YnaYC4uLgi5T799FPi4+MJDw/Hz8+Pp556qsTLOH9ZLVu2dCdpgPj4eJxOJ/v27XOPa9q0qcclvBEREaSkpJRoGenp6Zw4cYL4+HiP8fHx8ezduxdw7V7fvn07DRs2ZMSIESxbtsxd7q677iI7O5t69erx4IMPsmDBAgoKru5tp6VHfQHNx7U7xphXvvcRF0Jco/7fidLPY/z7xkw06uWqQ7ugXzTS8z4SV2Lw4ME88sgjzJgxg1mzZlG/fn1uvPFGAF566SVeffVVpk+fTvPmzfH19WXkyJHk5eWV2/LXr1/PwIEDmTRpEt26dSMwMJB58+bx8ssvl9syzmc2mz2GNU3D6XSWW/1t2rTh0KFDfPfdd6xYsYJ+/fqRkJDA559/Tu3atdm3bx8rVqxg+fLlPPzww+49GhfGVV6kR30Bg82VqE35mZcpKYSoEiy+pX8Zz+sDGU2ucecfn75UvWXQr18/DAYDn3zyCR9++CH333+/+3j1unXr6N27N//+979p2bIl9erV47fffitx3Y0bN+bYsWMkJSW5x23YsMGjzE8//UR0dDTjxo2jXbt2xMTEcOTIEc/mWiw4HI7LLmvHjh1kZf19/H7dunUYDAYaNmxY4pgvJSAggMjIyCKP2Fy3bh1NmjTxKNe/f3/eeecdPv30U7744gtOnz4NgM1mo1evXrz22musXr2a9evXF7mBV3mSHvUFTL5BAFgLpEcthLg2+Pn50b9/f8aOHUt6ejqDBg1yT4uJieHzzz/np59+Ijg4mGnTpnHy5EmPpHQpCQkJXHfddSQmJvLSSy+Rnp7OuHHjPMrExMRw9OhR5s2bR/v27fn2229ZsGCBR5k6depw6NAhtm/fTq1atfD39/e4JTTAwIEDmTBhAomJiUycOJE///yTRx55hHvuucd9fLo8jB49mgkTJlC/fn1atWrFrFmz2L59O3PmzAFg2rRpRERE0Lp1awwGA/Pnzyc8PJygoCBmz56Nw+EgNjYWu93Oxx9/jM1m8ziOXd6kR32BgmqN6JQ7nfE139U7FCGEKLHBgwdz5swZunXr5nE8+amnnqJNmzZ069aNzp07Ex4eTp8+fUpcr8FgYMGCBWRnZ9OhQwceeOABnnvuOY8yt912G//9738ZPnw4rVq14qeffuLpp5/2KHPHHXfQvXt3brrpJmrUqFHsJWJ2u52lS5dy+vRp2rdvz5133kmXLl144403SrcyLmPEiBGMGjWKxx57jObNm7NkyRIWLVpETEwM4DqD/cUXX6Rdu3a0b9+ew4cPs3jxYgwGA0FBQbzzzjvEx8fTokULVqxYwddff01ISEi5xng+TSmlrlrtV9kff/xB7dq1OXbsWJGL/cvqm50nGP7JNmLrVuPT/xQ9YUIIUfnk5ORw6NAh6tatW+Kn+QlxOZd6X5Umf0mP+gL+Pq6TAdJzru5ZfEIIIURJyDHqCwT4mPiv6XOi0zMhsyH4heodkhBCiCpMEvUFAmxm7jZ+T5gjFTKSJFELIYTQlSTqC/j7mJhV0B2Lls+jthA5NiCEEEJXkqgvEOBjZqbjNgAe8AnDX+d4hBBCVG3SYbyAj9mIxeRaLXJCmRBVS3ne3UqI8no/SY+6GLWtORgcKZw99QcExegdjhDiKrNYLBgMBk6cOEGNGjWwWCzuO3sJUVpKKfLy8vjzzz8xGAxYLJYrqk8SdTH+q33CP63L+GPXSGgwSe9whBBXmcFgoG7duiQlJXHiRBnu7S1EMex2O1FRURgMV7bzWhJ1MfLN/lAADnkmtRBVhsViISoqioKCgsvek1qIyzEajZhMpnLZMyOJuhgFFn/IlmdSC1HVaJqG2Wy+ak9BEqIs5GSyYiiL65nU5EiPWgghhL4kURfHx3VRliFPetRCCCH0JYm6GJpPEACmfHnUpRBCCH1Joi6G0R4EgDk/U99AhBBCVHmSqIthtgcCYHFIohZCCKEvSdTFsPoFA2BzZOkciRBCiKpOEnUxfPxdidpCHhTk6hyNEEKIqkzXRD1z5kxatGhBQEAAAQEBxMXF8d133+kZEgA2v6C/B+RaaiGEEDrSNVHXqlWLKVOmsGXLFn7++WduvvlmevfuzS+//KJnWATYfchQNtdAriRqIYQQ+tH1zmS9evXyGH7uueeYOXMmGzZsoGnTpjpFBQE2ExnY8CcblZOG3JpfCCGEXrzmFqIOh4P58+eTlZVFXFxcsWVyc3PJzf37mHFGxtW5zjnAx8xteWPJw8Syao2xXZWlCCGEEJene6LetWsXcXFx5OTk4Ofnx4IFC2jSpEmxZSdPnsykSVf/aVZ2i5HDWi0cTkV6voZNMrUQQgid6H7Wd8OGDdm+fTsbN25k6NChJCYmsmfPnmLLjh07lrS0NPfrYuWulKZp+Pu4fsNk5ORflWUIIYQQJaF7j9pisdCgQQMA2rZty+bNm3n11Vd56623ipS1Wq1YrVb3cHr61TvRq4dpG1GmXTgPKgj951VbjhBCCHEpuveoL+R0Oj2OQ+ulk7adoaavMR/foHcoQgghqjBde9Rjx46lR48eREVFkZGRwSeffMLq1atZunSpnmEB8Ju9DclZiiYBzamrdzBCCCGqLF0TdUpKCvfeey9JSUkEBgbSokULli5dyi233KJnWAD8Wu0mliY14f8CmlH8OehCCCHE1adron7vvff0XPwlBfiYAUiXk8mEEELoyOuOUXuLQKtGKGcg9ZjeoQghhKjCdD/r21s1y9nCUz4jOb7vOmCz3uEIIYSooqRHfRGmwmdSF8gzqYUQQuhHEvVFWHxdj7r0cUiiFkIIoR9J1BdhPfeoS5szC5TSNxghhBBVliTqi/DxrwaACQfkZ+scjRBCiKpKEvVF+PkH4lDnHnApz6QWQgihE0nUFxFgs5BZ+IDLnDR9gxFCCFFllSlRHzt2jD/++MM9vGnTJkaOHMnbb79dboHpLcDHTAZ2APKzUvUNRgghRJVVpkT9r3/9i1WrVgGQnJzMLbfcwqZNmxg3bhzPPPNMuQaoFz8fE+nKF4DsjNM6RyOEEKKqKlOi3r17Nx06dADgs88+o1mzZvz000/MmTOH2bNnl2d8ujEaNM5qrh51TmaqvsEIIYSossqUqPPz893PhV6xYgW33XYbAI0aNSIpKan8otNZttHVo87LOqNzJEIIIaqqMiXqpk2b8uabb/LDDz+wfPlyunfvDsCJEycICQkp1wD1lGf0A+QYtRBCCP2UKVG/8MILvPXWW3Tu3JkBAwbQsmVLABYtWuTeJV4Z5JkDAHBky1nfQggh9FGmh3J07tyZU6dOkZ6eTnBwsHv8kCFDsNvt5Rac3lYH38UbZ2J5oGYnGugdjBBCiCqpTD3q7OxscnNz3Un6yJEjTJ8+nX379hEaGlquAeopLyCKX1RdTqkAvUMRQghRRZUpUffu3ZsPP/wQgNTUVGJjY3n55Zfp06cPM2fOLNcA9RTg49rhkJ6Tr3MkQgghqqoyJeqtW7dy/fXXA/D5558TFhbGkSNH+PDDD3nttdfKNUA91dZOMtS4iJhjn+sdihBCiCqqTIn67Nmz+Pv7A7Bs2TJuv/12DAYD//jHPzhy5Ei5BqinSMcJxpjn0TblS71DEUIIUUWVKVE3aNCAhQsXcuzYMZYuXUrXrl0BSElJISCg8hzPVYHRzC+4gc22TnqHIoQQoooqU6IeP348jz/+OHXq1KFDhw7ExcUBrt5169atyzVAPWk1Yhhd8BCf+NytdyhCCCGqqDJdnnXnnXfSqVMnkpKS3NdQA3Tp0oW+ffuWW3B685eTyYQQQuisTIkaIDw8nPDwcPdTtGrVqlWpbnYCEGA1YSMHa3Y2OB1gMOodkhBCiCqmTLu+nU4nzzzzDIGBgURHRxMdHU1QUBDPPvssTqezvGPUTYDNzE7rg3yVOxgyKs89zIUQQlw7ytSjHjduHO+99x5TpkwhPj4egB9//JGJEyeSk5PDc889V65B6iXAZiYDG9XIxJGdhjGwlt4hCSGEqGLKlKg/+OAD3n33XfdTswBatGhBzZo1efjhhytNovb3MZOk7FTTMsnOOINfuN4RCSGEqGrKtOv79OnTNGrUqMj4Ro0acfr06RLXM3nyZNq3b4+/vz+hoaH06dOHffv2lSWkq8JiMpCpuR51mZ0hj7oUQghR8cqUqFu2bMkbb7xRZPwbb7xBixYtSlzPmjVrGDZsGBs2bGD58uXk5+fTtWtXsrKyyhLWVZFtcCXq3MyS/wARQgghykuZdn2/+OKL9OzZkxUrVrivoV6/fj3Hjh1j8eLFJa5nyZIlHsOzZ88mNDSULVu2cMMNN5QltHKXY/SFAsjLTNU7FCGEEFVQmXrUN954I7/99ht9+/YlNTWV1NRUbr/9dn755Rc++uijMgeTluZ67nO1atWKnZ6bm0t6err7lZGRUeZllVSeyXWr1AJ5JrUQQggdlPk66sjIyCInje3YsYP33nuPt99+u9T1OZ1ORo4cSXx8PM2aNSu2zOTJk5k0aVKZ4i2rfLM/5IBTErUQQggdlKlHfTUMGzaM3bt3M2/evIuWGTt2LGlpae7Xnj17rnpcTovr3uVKErUQQggdlLlHXZ6GDx/ON998w9q1a6lV6+LXKlutVqxWq3s4PT39qsfmtLp2fRvyrv6yhBBCiAvpmqiVUjzyyCMsWLCA1atXU7duXT3DKZZmDQTAkHf1j4cLIYQQFypVor799tsvOT01NbVUCx82bBiffPIJX331Ff7+/iQnJwMQGBiIzWYrVV1Xi8HuStSmfEnUQgghKl6pEnVgYOBlp997770lrm/mzJkAdO7c2WP8rFmzGDRoUGlCu2qMtiAALJKohRBC6KBUiXrWrFnlunClVLnWdzXkhzZnQN44okJr84LewQghhKhyvOJkMm9mC6zOemdTMhwBeocihBCiCvKay7O8VYCPGYD07AKdIxFCCFEVSY/6MgKsRgYaV1AjOxfyYsFi1zskIYQQVYgk6ssIsFt42vQRPioflTUGzRKtd0hCCCGqEEnUlxHgY+ZrRxyaBrc6DEh/WgghREWSRH0ZPmYDY51DKXAq4s3VJVELIYSoUHIy2WVomkaAzXVCWUaOnFAmhBCiYkmiLoEAqxEfcsnIyNQ7FCGEEFWMJOoSeLZgGr/63Iffnjl6hyKEEKKKkURdAg6T68i046w86lIIIUTFkkRdAgWFz6TOkUddCiGEqFiSqEvAaXE9k5pc6VELIYSoWJKoS8Lq6lFrudKjFkIIUbEkUZeAZjv3TOo8edSlEEKIiiWJugSMhYm6QC7PEkIIUbEkUZeAyTcIAGuB9KiFEEJULEnUJWDxDQbA5szSORIhhBBVjSTqEvDxCwIkUQshhKh4kqhLwB4QAoCNXHDk6xyNEEKIqkQSdQn4BgT/PSA3PRFCCFGBJFGXgL+vjbPKCkBu1hmdoxFCCFGVyPOoS8DPYuKBghHkKDOvmkKooXdAQgghqgxJ1CVgMGj8bG5Pek4B6Q6zJGohhBAVRnZ9l5C/jxmA9Gw5mUwIIUTFkR51CcWbfsVkPIAjOQii4vUORwghRBUhPeoS6lOwhOfN7+Hzx496hyKEEKIK0TVRr127ll69ehEZGYmmaSxcuFDPcC7pD3tjljnactoUqncoQgghqhBdE3VWVhYtW7ZkxowZeoZRIhvCBzAk/zH2Bt6gdyhCCCGqEF2PUffo0YMePXroGUKJBRSeTJYjJ5MJIYSoONfUyWS5ubnk5ua6hzMyKu5pVgE2M6DIPJtTYcsUQgghrqmTySZPnkxgYKD71aRJkwpbdsu0VeyzJvKv/aMqbJlCCCHENZWox44dS1pamvu1Z8+eClu2xceOVSvAXJBZYcsUQgghrqld31arFavV6h5OT6+4B2RYfAMB8HFIohZCCFFxrqketZ6sfq4naNmckqiFEEJUHF171JmZmRw4cMA9fOjQIbZv3061atWIiorSMbKifPyqAWBXZ3WORAghRFWia6L++eefuemmm9zDo0a5TtRKTExk9uzZOkVVPHugq0dtJR/yc8Dso3NEQgghqgJdE3Xnzp1RSukZQon5+we7/y84m4opMFzHaIQQQlQVcoy6hPzsVtKVDYCs9DM6RyOEEKKqkERdQmajgSzsAGRnSKIWQghRMSRRl0KWwReA7MzTOkcihBCiqpBEXQrZBj8A8jIkUQshhKgYkqhLIcVcCwDfY6t1jUMIIUTVIYm6FPaE9QIg+NgKKMi9TGkhhBDiykmiLoXYG3syOn8IN+e9TGqepnc4QgghqgBJ1KXQvm41dofexsl8O5/9fEzvcIQQQlQBkqhLQdM0BnWMBuDD9Udw5MvubyGEEFeXJOpS6t2qJjfZDvBa1miS5zykdzhCCCEqOUnUpeRjNnJT40jaGA4QfGQJ5GfrHZIQQohKTBJ1GdyccCvj8gdzQ/bL7D9doHc4QgghKjFJ1GVQq5ovpxr9i1ME8sH6w3qHI4QQohKTRF1GiR3rAPDl1uOkn5Xd30IIIa4OSdRlFFcvhNtCTvCemsTJjx7QOxwhhBCVlCTqMtI0jVtbhBNn3ENU0lKcWXL/byGEEOVPEvUVuKFzd34lGiv5HFjxrt7hCCGEqIQkUV8Bu9XM4ei7APDd9REopXNEQgghKhtJ1FeoabcHOaus1Cw4yvGd3+sdjhBCiEpGEvUVqh0Zzhb/mwE4teYtnaMRQghR2UiiLgd+nR4EoNFf35N5JkXnaIQQQlQmkqjLQasON7HfUA+rls/eJdKrFkIIUX4kUZcDzWDgr0YDAAj7bS5Oh1PniIQQQlQWkqjLSbPuD3BWWYlSx9n502K9wxFCCFFJSKIuJ34B1dhbo5trYPUUlq/bQE6+Q9+ghBBCXPMkUZejiIThFCgDrRy7WPTt17T/vxWM+Xwnmw6dRsk11kIIIcrAKxL1jBkzqFOnDj4+PsTGxrJp0ya9QyqTyEaxnL5jPnurd2On/w1k5Bbw6c/H+OrdZ/noucG8+81ajvyVpXeYQgghriEmvQP49NNPGTVqFG+++SaxsbFMnz6dbt26sW/fPkJDQ/UOr9RCWyQQ2iKBVU7FpsOnWbDlKA/t/obaBSk8vr46//djBq1qB9G+ej61Ay2EhkdQq0Y1okLsBPiY9Q5fCCGEl9GUzvtkY2Njad++PW+88QYATqeT2rVr88gjj/Dkk09ect4//viD2rVrc+zYMWrVqlUR4Zae00Hu7kWc/ulDnjb9l+8PZuBUMNn0DgNMqwDIVhZO40+G5k+uOZACazCaTwAGsw2jxQeT1Y7Jaofq1+Fs2JMAmwl/HzPm374BNBz1bgazDQDtrwNoGSdAM6BpJjCZMBjMaEYTBqMJzWhCM5jAYAKDEdDAaAG/Gn/HnH4CnA7wCwOTxTUuPxsceWAwu+Y1mkHTKnZdCnEeh1ORne8gO89BTr4Dk1HDZjbiYzZiNRnQ5P1Z7nILHGTlOsjMKSAzt4Ds/AKsJiO+VhN+514+Zln3JVGa/KVrjzovL48tW7YwduxY9ziDwUBCQgLr168vUj43N5fc3Fz3cEZGRoXEeUUMRqwt+hLRoi/vAifTc/hx/ykabvTFkWLAiBOblkdN/gL+gnxcr8yiVS1ztGXId/7u4YPWQRg1RfucGfxJMAATTB9wn2lpqULcohoxiGcwGDSMBo1ljgeoTir/Nr/CIWMdNA0SC+bzYP4nHvM5MFCACQUoNJxoKDRAwwkcURH0cz6PUymMBo0PtEnU047zuPYYOwxNMGjQU61hmGOOu051Xh1o4PoVqbmnAWTgy/3Wl13jlOLp/Fdppn5juvE+1hvboWkacc4tPJ7/1rnaCmt0RXqusnM1K84fcavpHTSDCYMGTxS8yfXOzbxvGcgSyy0YDRpNHPt4OmvyudKFEblmV+dXfB4F9NOmcppAnErxiJpHb20Vc7WefGjog0GD2iTzVsF4zv96U9r57XatX9DOjXdF/v98nuKwVhOHU9E7fzF3FixmmdaRmVo/lIIAspilni5Sr+aO7fwpf///kuVhfjVdB8AN+T9yb/7n/GxowWumQTiVQin4MP9x97o9t7lctZyLW/Oo1jX0gS2RLZa2ALTK3879Z9/noLE+r/k/6l72c2n/D3/l+dlWChQKp8K9/PO7GG8W9GKRsyMATbVDvGR+myStBk+YnsTHbMTHbGBSzgtEOJOKbpxi1nlh7Ess3Vhs6wlAuDOZsRmTOavZGRc4xT3Pw5lvEFPwG6XxkyWe+fb+APg6M/m/9P8HwGOBr+DUjGga3Js1m1Z5W0tV705LS2b7Dna1RcG01JFoOJkQ8CzphkAAbs/+nOtz15aoPqXAoWCPimZM/oPkO1wr7EPzZIK1DB7Lf4TDKgKAu43fM9C4Ag0NgwEMmnbudfH6U4xhTPYf5x4ek/E8EY4kZvgOZ7+5IQDxuT/QL/vTS8ZZ+ElBKZRSZGBnsPH/yCtwku9QPM/rtNL285zjXtbSFqNB43rDTp7UZqNx7nNw3o8Lzf05K6zb9Qb/yH4PbW8ZSM8WESVaf+VF10R96tQpHA4HYWFhHuPDwsL49ddfi5SfPHkykyZNqqjwroqwAB/uaFsL2s5xfQpy0+HsabLT/uTPlCRS/0om88yf5Gen4cjLQeVlo/Kz0Qpy2KvqUM1iIS07H4dTsUVdh1E5yePvXeZ/qkD2OWthxIkBJyYcGLVzf88Nu8Y7MeI6Kz3XaSAjv8BdR47VRA5mUjLzOK6yAcgy5RR5txhxYiTvom21q7Nkn3fmu78lgxAtjZzcXE47XfM5jJmEmi/yiNCL7Os5o/w4nprtHg40/0ltYxJ5Z9M54cxxxWvIINzy50Vju5iUzDwUrnVhNKcTYjxDZmYGBx2ucwuCtHRCrKV/pGlmdh5p5ANgMWUSZjqDIT+T0wWu9RCoZRN6Yb0X29d13vjkMxkcUWdd8RrPUNd8HL/806QWuJalkUsDn2Mlq/c86RlpHHG66nUaTxNjPsyBvBokZeW4y8RYD2PUPH/4XK7+M6f/5BdnOgC1Daeob/mdU/kWdqenu8tEWo9QQ0u7dIDnfssVCjVlYnEYyHM4sZNLE8MRrM48/sr6+/1Z3XKM+oZjReu6hIKMZH4544otRztDA+tBzig/dh3/O74A81EaGA+Wqt6NGXXYdcZVRxAZNPBxzb/rRDrOc6cOWc3HSl3v/sxq7Dzzd2z1rAcwaorfklIp/DTcYTpOA1Pp6k13mtxJGqCx4Sg1tDTqBBrJcfqQmVtAqCOV5obDf8903u/ii9Hyz7Ir/e94q1uOUt9wjKRTf7HL6RrfwphCPfOhUsV7RvlxKvvvbR9mPk1dw0lsBdnkOZ3gAKMhk3qW457xnq+Y2NP++pPTZy/+nXe16Lrr+8SJE9SsWZOffvqJuLg49/gnnniCNWvWsHHjRo/yF/aojx8/TpMmTbx71/dVoJQiJ9+JusynQJ3rfTiVa54L/zqUwuFUOJ2c+9+Jw+napegsnKZcS1EOB5rKB0cBmrMAVAE4CsCRj8kARgMYURg0XMOawmC0oIJdPXKlwHDmIM78XPL8a+M02XEohXb2NMaM4+d6R65PtnKea5n6u41KndcrNpjIqdEScP0I9jn9G6b8dHIC6lFgq4ZTgSHnDOa0w655C3v7yrXHRjv3K1/TDBg01y9pg6ahaZAT3AgnrvVmSD+GITedXFsYuZZgnE4FeVnYs466eg0aaAZcf9HQzvVUjee6EH8vR6OgWgyayYJB0zBmnsBw9i/ybTXIt4e61nFeDubUA+dtMyfKeW4dKIVSznO9SAco13YxapBTrQma1RejQcMn6zg+Wcdx+oXhDK7vWu8F+fgkbXL1Rp0ATndvtPCjrwrfLPz93ZQV0gyHNQhQWLOSsKUdxGEPIa96M8DVW/L7Y41rr8e5+hxO13uq8D3mPPf+cZ73FZMV1JA8m+vcE3P2KfxS91JgCSAjpKW7TGDKRgyOfI/3ssGgYTUZMBsNWM/t2raaDFiMrnFa9RgIqk2Bw0lOxmkKjm0hV7OSVqMt2XkOsvMdWJN+xlhw1l2nhvJI9u4u+nkfq2y/KLID6qCUwpifRcCfW1AGE2fCO7rL+P+1A3PuZX5YXCDHN4KzgTGuOBx5BJ/cAMDpiOspDMrvzB4sOadKVW+eTwiZwU3dw9WS1gBwJuwfKKMVAHvafnyyTpSoPqOm4WM2YPWrhjE6Fl+rCV+LEdORteDIh6h/gNW1l8956iB5KQdchyPyXYcjcvIdHgn+Qg6jjbTQ9u7tEPjnFowFZ0mv1owCq2svoTUrCXv65X9YGA0GjEYDJoMRk8VCfs1/YDZqmI0GbKn7MOVnkB9Yj3yfEBxOhco6heHUPpRynvsedJ77XgTO/VXKiXKqc98JkOlfj+g69akVbC/R+ruU0uz61jVR5+XlYbfb+fzzz+nTp497fGJiIqmpqXz11VeXnP+aOEYthBBCXKA0+UvXy7MsFgtt27Zl5cqV7nFOp5OVK1d69LCFEEKIqkr3y7NGjRpFYmIi7dq1o0OHDkyfPp2srCzuu+8+vUMTQgghdKd7ou7fvz9//vkn48ePJzk5mVatWrFkyZIiJ5gJIYQQVZHuiRpg+PDhDB8+XO8whBBCCK/jFbcQFUIIIUTxvKJHXVZO1/UmJCUlXaakEEII4T0K81ZhHruUazpRnzx5EoAOHTroHIkQQghReidPniQqKuqSZXS/1/eVKCgoYNu2bYSFhWEwXPle/IyMDJo0acKePXvw9/e//AxeSNrgHaQN3kHa4B2kDUU5nU5OnjxJ69atMZku3We+phN1eUtPTycwMJC0tDQCAgL0DqdMpA3eQdrgHaQN3kHacGXkZDIhhBDCi0miFkIIIbyYJOrzWK1WJkyYgNVq1TuUMpM2eAdpg3eQNngHacOVkWPUQgghhBeTHrUQQgjhxSRRCyGEEF5MErUQQgjhxSp1op4xYwZ16tTBx8eH2NhYNm3adMny8+fPp1GjRvj4+NC8eXMWL17sMV0pxfjx44mIiMBms5GQkMD+/fuvZhNK1YZ33nmH66+/nuDgYIKDg0lISChSftCgQWia5vHq3r2717Rh9uzZReLz8fHxKKPHdoDStaNz585F2qFpGj179nSXqchtsXbtWnr16kVkZCSaprFw4cLLzrN69WratGmD1WqlQYMGzJ49u0iZ0n7GrkRp2/Dll19yyy23UKNGDQICAoiLi2Pp0qUeZSZOnFhkGzRq1Mhr2rB69epi30fJycke5bx5OxT3Ptc0jaZNm7rLVPR2mDx5Mu3bt8ff35/Q0FD69OnDvn37LjufXjmi0ibqTz/9lFGjRjFhwgS2bt1Ky5Yt6datGykpKcWW/+mnnxgwYACDBw9m27Zt9OnThz59+rB79253mRdffJHXXnuNN998k40bN+Lr60u3bt3IycnxijasXr2aAQMGsGrVKtavX0/t2rXp2rUrx48f9yjXvXt3kpKS3K+5c+delfjL0gaAgIAAj/iOHDniMb2it0NZ2vHll196tGH37t0YjUbuuusuj3IVtS2ysrJo2bIlM2bMKFH5Q4cO0bNnT2666Sa2b9/OyJEjeeCBBzwSXVm2bUW2Ye3atdxyyy0sXryYLVu2cNNNN9GrVy+2bdvmUa5p06Ye2+DHH3+8GuEDpW9DoX379nnEGBoa6p7m7dvh1Vdf9Yj92LFjVKtWrchnoSK3w5o1axg2bBgbNmxg+fLl5Ofn07VrV7Kysi46j645QlVSHTp0UMOGDXMPOxwOFRkZqSZPnlxs+X79+qmePXt6jIuNjVX/+c9/lFJKOZ1OFR4erl566SX39NTUVGW1WtXcuXOvQgtK34YLFRQUKH9/f/XBBx+4xyUmJqrevXuXd6gXVdo2zJo1SwUGBl60Pj22g1JXvi1eeeUV5e/vrzIzM93jKnpbFALUggULLlnmiSeeUE2bNvUY179/f9WtWzf38JWukytRkjYUp0mTJmrSpEnu4QkTJqiWLVuWX2ClUJI2rFq1SgHqzJkzFy1zrW2HBQsWKE3T1OHDh93j9NwOSimVkpKiALVmzZqLltEzR1TKHnVeXh5btmwhISHBPc5gMJCQkMD69euLnWf9+vUe5QG6devmLn/o0CGSk5M9ygQGBhIbG3vROiu6DRc6e/Ys+fn5VKtWzWP86tWrCQ0NpWHDhgwdOpS//vqrXGMvVNY2ZGZmEh0dTe3atenduze//PKLe1pFb4cracf53nvvPe6++258fX09xlfUtiity30eymOdVDSn00lGRkaRz8P+/fuJjIykXr16DBw4kKNHj+oU4cW1atWKiIgIbrnlFtatW+cefy1uh/fee4+EhASio6M9xuu5HdLS0gCKvDfOp2eOqJSJ+tSpUzgcDsLCwjzGh4WFFTm2Uyg5OfmS5Qv/lqbOK1GWNlxozJgxREZGerxxunfvzocffsjKlSt54YUXWLNmDT169MDhcJRr/FC2NjRs2JD333+fr776io8//hin00nHjh35448/gIrfDnDl22LTpk3s3r2bBx54wGN8RW6L0rrY5yE9PZ3s7OxyeX9WtKlTp5KZmUm/fv3c42JjY5k9ezZLlixh5syZHDp0iOuvv56MjAwdI/1bREQEb775Jl988QVffPEFtWvXpnPnzmzduhUon++JinTixAm+++67Ip8FPbeD0+lk5MiRxMfH06xZs4uW0zNHXNOPuRQXN2XKFObNm8fq1as9Tsa6++673f83b96cFi1aUL9+fVavXk2XLl30CNVDXFwccXFx7uGOHTvSuHFj3nrrLZ599lkdIyu79957j+bNmxd5HKu3b4vK5JNPPmHSpEl89dVXHsd3e/To4f6/RYsWxMbGEh0dzWeffcbgwYP1CNVDw4YNadiwoXu4Y8eOHDx4kFdeeYWPPvpIx8jK5oMPPiAoKIg+ffp4jNdzOwwbNozdu3df1WPiV6pS9qirV6+O0Wh0P6+60MmTJwkPDy92nvDw8EuWL/xbmjqvRFnaUGjq1KlMmTKFZcuW0aJFi0uWrVevHtWrV+fAgQNXHPOFrqQNhcxmM61bt3bHV9HbAa6sHVlZWcybN69EXzZXc1uU1sU+DwEBAdhstnLZthVl3rx5PPDAA3z22WdFdl1eKCgoiOuuu84rtsHFdOjQwR3ftbQdlFK8//773HPPPVgslkuWrajtMHz4cL755htWrVpFrVq1LllWzxxRKRO1xWKhbdu2rFy50j3O6XSycuVKj97a+eLi4jzKAyxfvtxdvm7duoSHh3uUSU9PZ+PGjRets6LbAK6zDp999lmWLFlCu3btLrucP/74g7/++ouIiIhyift8ZW3D+RwOB7t27XLHV9HbAa6sHfPnzyc3N5d///vfl13O1dwWpXW5z0N5bNuKMHfuXO677z7mzp3rcWncxWRmZnLw4EGv2AYXs337dnd818p2ANeZ1gcOHCjRj9arvR2UUgwfPpwFCxbw/fffU7du3cvOo2uOuKJT0bzYvHnzlNVqVbNnz1Z79uxRQ4YMUUFBQSo5OVkppdQ999yjnnzySXf5devWKZPJpKZOnar27t2rJkyYoMxms9q1a5e7zJQpU1RQUJD66quv1M6dO1Xv3r1V3bp1VXZ2tle0YcqUKcpisajPP/9cJSUluV8ZGRlKKaUyMjLU448/rtavX68OHTqkVqxYodq0aaNiYmJUTk6OV7Rh0qRJaunSpergwYNqy5Yt6u6771Y+Pj7ql19+8WhnRW6HsrSjUKdOnVT//v2LjK/obZGRkaG2bdumtm3bpgA1bdo0tW3bNnXkyBGllFJPPvmkuueee9zlf//9d2W329Xo0aPV3r171YwZM5TRaFRLlixxl7ncOtG7DXPmzFEmk0nNmDHD4/OQmprqLvPYY4+p1atXq0OHDql169aphIQEVb16dZWSkuIVbXjllVfUwoUL1f79+9WuXbvUo48+qgwGg1qxYoW7jLdvh0L//ve/VWxsbLF1VvR2GDp0qAoMDFSrV6/2eG+cPXvWXcabckSlTdRKKfX666+rqKgoZbFYVIcOHdSGDRvc02688UaVmJjoUf6zzz5T1113nbJYLKpp06bq22+/9ZjudDrV008/rcLCwpTValVdunRR+/bt85o2REdHK6DIa8KECUoppc6ePau6du2qatSoocxms4qOjlYPPvjgVftAl6UNI0eOdJcNCwtTt956q9q6datHfXpsh9K2Qymlfv31VwWoZcuWFamrordF4WU+F74KY05MTFQ33nhjkXlatWqlLBaLqlevnpo1a1aRei+1TvRuw4033njJ8kq5LjmLiIhQFotF1axZU/Xv318dOHDAa9rwwgsvqPr16ysfHx9VrVo11blzZ/X9998Xqdebt4NSrsuUbDabevvtt4uts6K3Q3HxAx7vcW/KEfL0LCGEEMKLVcpj1EIIIURlIYlaCCGE8GKSqIUQQggvJolaCCGE8GKSqIUQQggvJolaCCGE8GKSqIUQQggvJolaCCGE8GKSqIUQV0zTNBYuXKh3GEJUSpKohbjGDRo0CE3Tiry6d++ud2hCiHIgz6MWohLo3r07s2bN8hhntVp1ikYIUZ6kRy1EJWC1WgkPD/d4BQcHA67d0jNnzqRHjx7YbDbq1avH559/7jH/rl27uPnmm7HZbISEhDBkyBAyMzM9yrz//vs0bdoUq9VKREQEw4cP95h+6tQp+vbti91uJyYmhkWLFrmnnTlzhoEDB1KjRg1sNhsxMTFFflgIIYoniVqIKuDpp5/mjjvuYMeOHQwcOJC7776bvXv3ApCVlUW3bt0IDg5m8+bNzJ8/nxUrVngk4pkzZzJs2DCGDBnCrl27WLRoEQ0aNPBYxqRJk+jXrx87d+7k1ltvZeDAgZw+fdq9/D179vDdd9+xd+9eZs6cSfXq1StuBQhxLbvi528JIXSVmJiojEaj8vX19Xg999xzSinXI/0eeughj3liY2PV0KFDlVJKvf322yo4OFhlZma6p3/77bfKYDC4H7sZGRmpxo0bd9EYAPXUU0+5hzMzMxWgvvvuO6WUUr169VL33Xdf+TRYiCpGjlELUQncdNNNzJw502NctWrV3P/HxcV5TIuLi2P79u0A7N27l5YtW+Lr6+ueHh8fj9PpZN++fWiaxokTJ+jSpcslY2jRooX7f19fXwICAkhJSQFg6NCh3HHHHWzdupWuXbvSp08fOnbsWKa2ClHVSKIWohLw9fUtsiu6vNhsthKVM5vNHsOapuF0OgHo0aMHR44cYfHixSxfvpwuXbowbNgwpk6dWu7xClHZyDFqIaqADRs2FBlu3LgxAI0bN2bHjh1kZWW5p69btw6DwUDDhg3x9/enTp06rFy58opiqFGjBomJiXz88cdMnz6dt99++4rqE6KqkB61EJVAbm4uycnJHuNMJpP7hK358+fTrl07OnXqxJw5c9i0aRPvvfceAAMHDmTChAkkJiYyceJE/vzzTx555BHuuecewsLCAJg4cSIPPfQQoaGh9OjRg4yMDNatW8cjjzxSovjGjx9P27Ztadq0Kbm5uXzzzTfuHwpCiEuTRC1EJbBkyRIiIiI8xjVs2JBff/0VcJ2RPW/ePB5++GEiIiKYO3cuTZo0AcBut7N06VIeffRR2rdvj91u54477mDatGnuuhITE8nJyeGVV17h8ccfp3r16tx5550ljs9isTB27FgOHz6MzWbj+uuvZ968eeXQciEqP00ppfQOQghx9WiaxoIFC+jTp4/eoQghykCOUQshhBBeTBK1EEII4cXkGLUQlZwc3RLi2iY9aiGEEMKLSaIWQgghvJgkaiGEEMKLSaIWQgghvJgkaiGEEMKLSaIWQgghvJgkaiGEEMKLSaIWQgghvJgkaiGEEMKL/X90bIOt2IPDgQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model to a file gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "# Let's train this cutie model \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "print(\"Beginning training\")\n",
    "\n",
    "model_file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "\n",
    "if os.path.exists(model_file_name):\n",
    "    model.load_state_dict(torch.load(model_file_name))\n",
    "    model.eval()\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    torch.manual_seed(123)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "    num_epochs = 2\n",
    "    \n",
    "    train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=num_epochs, eval_fr=5, eval_iter=5,\n",
    "        start_context=format_input(val_data.iloc[0]), tokenizer=tokenizer\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "    \n",
    "    # Plot losses...\n",
    "    epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "    plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "    print(f\"Saving trained model to a file {model_file_name}\")\n",
    "    torch.save(model.state_dict(), model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf6b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "## Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> ................................................................................................................................................................................................................................................................\n",
      "-------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "## Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n",
      "-------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "## Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> '.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.'.']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 17/110 [2:05:18<11:25:29, 442.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m entry_dict \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     28\u001b[0m input_text \u001b[38;5;241m=\u001b[39m format_input(entry_dict)\n\u001b[1;32m---> 30\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_to_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# stays on CPU\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASE_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50256\u001b[39;49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m token_ids_to_txt(token_ids, tokenizer)\n\u001b[0;32m     39\u001b[0m response_text \u001b[38;5;241m=\u001b[39m generated_text[\u001b[38;5;28mlen\u001b[39m(input_text):]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Vidushi\\OneDrive\\Desktop\\LLM\\Pretraining.py:105\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(model, idx, max_new_tokens, context_size, temperature, top_k, eos_id)\u001b[0m\n\u001b[0;32m    103\u001b[0m idx_cond\u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39mcontext_size:]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 105\u001b[0m     logits\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m logits\u001b[38;5;241m=\u001b[39m logits[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vidushi\\OneDrive\\Desktop\\LLM\\GPT_architecture.py:221\u001b[0m, in \u001b[0;36mGPTModel.forward\u001b[1;34m(self, in_idx)\u001b[0m\n\u001b[0;32m    219\u001b[0m x\u001b[38;5;241m=\u001b[39m tok_embeds\u001b[38;5;241m+\u001b[39mpos_embeds\n\u001b[0;32m    220\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb(x)\n\u001b[1;32m--> 221\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm(x)\n\u001b[0;32m    223\u001b[0m logits\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vidushi\\OneDrive\\Desktop\\LLM\\GPT_architecture.py:162\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    160\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    161\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)\n\u001b[1;32m--> 162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_shortcut(x)\n\u001b[0;32m    164\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m shortcut\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vidushi\\OneDrive\\Desktop\\LLM\\GPT_architecture.py:90\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Preview a few examples\n",
    "for _, entry in test_data.head(3).iterrows():\n",
    "    entry_dict = entry.to_dict()\n",
    "    input_text = format_input(entry_dict)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),  # no .to(device)\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_txt(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry_dict['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text}\")\n",
    "    print(\"-------------\")\n",
    "\n",
    "# Generate responses for all test data\n",
    "model_responses = []\n",
    "for _, entry in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "    entry_dict = entry.to_dict()\n",
    "    input_text = format_input(entry_dict)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),  # stays on CPU\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_txt(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    model_responses.append(response_text)\n",
    "\n",
    "# Add new column to DataFrame\n",
    "test_data[\"model_response\"] = model_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37182eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
