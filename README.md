# LLM from scratch 🤖✨
 
Welcome to **Build-LLM-Playground** – my personal sandbox where I tinker with **language models**, piece by piece, while following the *"Build LLMs"* book. Think of it as a LEGO set, but for neural networks! 🧩💻  

---

## What’s Happening Here?  

- **Tokenization experiments** – turning text into numbers, because computers don’t speak English… yet.  
- **Transformers from scratch** – attention, feed-forward layers, layer normalization… all the juicy bits that make LLMs tick.  
- **Mini GPT models** – assemble, play, break, repeat. See what happens when your model tries to talk back.  
- **Gradient gymnastics** – check how learning actually happens inside these beasts.  
- **Memory & parameter detective work** – because size *does* matter (in MBs).  

---

## Getting Started

1. **Clone the repo**  
```bash
git clone https://github.com/yourusername/Build-LLM-Playground.git
cd Build-LLM-Playground
````

2. **Install dependencies**

```bash
pip install torch tiktoken transformers
```

3. **Run experiments**

```bash
python ch3_gpt_model/main.py
```

---

## A Few Notes

* This is purely for **fun and learning** – these models are tiny and not ready to take over the world. 🌍
* Some experiments sneak in Hugging Face models for comparison, but the goal is **hands-on building from scratch**.
* Curious minds and fellow tinkers are welcome! Pull requests, ideas, and memes encouraged. 😎

---

## Author

**Vin** – exploring the inner workings of LLMs, one line of code at a time. 🧠💡
