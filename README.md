# LLM from scratch ğŸ¤–âœ¨
 
Welcome to **Build-LLM-Playground** â€“ my personal sandbox where I tinker with **language models**, piece by piece, while following the *"Build LLMs"* book. Think of it as a LEGO set, but for neural networks! ğŸ§©ğŸ’»  

---

## Whatâ€™s Happening Here?  

- **Tokenization experiments** â€“ turning text into numbers, because computers donâ€™t speak Englishâ€¦ yet.  
- **Transformers from scratch** â€“ attention, feed-forward layers, layer normalizationâ€¦ all the juicy bits that make LLMs tick.  
- **Mini GPT models** â€“ assemble, play, break, repeat. See what happens when your model tries to talk back.  
- **Gradient gymnastics** â€“ check how learning actually happens inside these beasts.  
- **Memory & parameter detective work** â€“ because size *does* matter (in MBs).  

---

## Getting Started

1. **Clone the repo**  
```bash
git clone https://github.com/yourusername/Build-LLM-Playground.git
cd Build-LLM-Playground
````

2. **Install dependencies**

```bash
pip install torch tiktoken transformers
```

3. **Run experiments**

```bash
python ch3_gpt_model/main.py
```

---

## A Few Notes

* This is purely for **fun and learning** â€“ these models are tiny and not ready to take over the world. ğŸŒ
* Some experiments sneak in Hugging Face models for comparison, but the goal is **hands-on building from scratch**.
* Curious minds and fellow tinkers are welcome! Pull requests, ideas, and memes encouraged. ğŸ˜

---

## Author

**Vin** â€“ exploring the inner workings of LLMs, one line of code at a time. ğŸ§ ğŸ’¡
